{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce Preprocessed versions of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows, Total Columns: (48854, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11321</th>\n",
       "      <td>1</td>\n",
       "      <td>Citing the near infinite number of celestial b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1</td>\n",
       "      <td>The airline industry is reeling following a sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25100</th>\n",
       "      <td>3</td>\n",
       "      <td>Basel III: How The Bank For International Sett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14851</th>\n",
       "      <td>2</td>\n",
       "      <td>You Wont Believe The Dire Warning Netanyahu Ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24790</th>\n",
       "      <td>3</td>\n",
       "      <td>Anonymous Operation: Bureau of Land Mismanagem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                                  1\n",
       "11321  1  Citing the near infinite number of celestial b...\n",
       "401    1  The airline industry is reeling following a sc...\n",
       "25100  3  Basel III: How The Bank For International Sett...\n",
       "14851  2  You Wont Believe The Dire Warning Netanyahu Ju...\n",
       "24790  3  Anonymous Operation: Bureau of Land Mismanagem..."
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file in\n",
    "train_path = './raw_data/fulltrain.csv'\n",
    "test_path = './raw_data/balancedtest.csv'\n",
    "df = pd.read_csv(train_path, header=None)\n",
    "test_df = pd.read_csv(test_path, header=None)\n",
    "\n",
    "print('Total rows, Total Columns: ' + str(df.shape))\n",
    "df.sample(5) # Random sample values to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows, Total Columns: (3000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>2</td>\n",
       "      <td>[Watch] Cowardly Ferguson Punk Runs His Foul M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>There are fans, and then there are super-fans....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>2</td>\n",
       "      <td>[Watch] John Bolton on Obama Hiding Russian Nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>2</td>\n",
       "      <td>Science Says: Ladies, Just Say No To Hot Guys ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>2</td>\n",
       "      <td>Americans And The Global Warming Public Relati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "1034  2  [Watch] Cowardly Ferguson Punk Runs His Foul M...\n",
       "6     1  There are fans, and then there are super-fans....\n",
       "821   2  [Watch] John Bolton on Obama Hiding Russian Nu...\n",
       "1158  2  Science Says: Ladies, Just Say No To Hot Guys ...\n",
       "1440  2  Americans And The Global Warming Public Relati..."
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Total rows, Total Columns: ' + str(test_df.shape))\n",
    "test_df.sample(5) # Random sample values to see"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text-Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Create set of stopwords for use in preprocessing\n",
    "stopword_set = set(stopwords.words('english'))\n",
    "# print(stopword_set)\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    tokenised_text = nltk.word_tokenize(text)\n",
    "    # Tag with Penn Treebank POS tags\n",
    "    tagged_text = nltk.pos_tag(tokenised_text)\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = []\n",
    "\n",
    "    for word in tagged_text:\n",
    "        pos_tag = get_wordnet_pos(word[1])\n",
    "        if pos_tag == '':\n",
    "            continue\n",
    "        new_word = lemmatizer.lemmatize(word=word[0], pos=pos_tag)\n",
    "        lemmatized_words.append(new_word)\n",
    "    lemmatized_text = ' '.join(lemmatized_words)\n",
    "    return lemmatized_text\n",
    "\n",
    "# Convert into wordnet compatible POS tags (j, v, n , a)\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# Fold to lower case\n",
    "def to_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def tokenise_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # print(tokens)\n",
    "    return tokens\n",
    "\n",
    "def remove_stopwords(text, stopword_set):\n",
    "    # Split by whitespace\n",
    "    split_text = text.split()\n",
    "    new_tokens = []\n",
    "    for token in split_text:\n",
    "        if token in stopword_set:\n",
    "            continue\n",
    "        new_tokens.append(token)\n",
    "    # Parse back into text\n",
    "    return ' '.join(new_tokens)\n",
    "\n",
    "# Remove all punctuations - Affects words such as U.S.A etc\n",
    "# Removal of stop words has to be done prior to punctuation removal\n",
    "def remove_punctuation(text):\n",
    "    depunctuated_text = text.translate(str.maketrans('','', string.punctuation))\n",
    "    return depunctuated_text\n",
    "\n",
    "# Prevent concatenation of statistics and names\n",
    "def replace_hyphens(text):\n",
    "    return text.replace('-', ' ')\n",
    "\n",
    "# Combine all processes into a single preprocess text function to call on df\n",
    "# Default one used for training\n",
    "def preprocess_text(text):\n",
    "    dehyphenated_text = replace_hyphens(text)\n",
    "    lowered_text = to_lower_case(dehyphenated_text)\n",
    "    initial_stopword_pass = remove_stopwords(lowered_text, stopword_set)\n",
    "    tokens = tokenise_text(initial_stopword_pass)\n",
    "    tokenised_text = ' '.join(tokens)\n",
    "    depunctuated_text = remove_punctuation(tokenised_text)\n",
    "    second_stopword_pass = remove_stopwords(depunctuated_text, stopword_set)\n",
    "    return second_stopword_pass\n",
    "\n",
    "# Testing dataset 1\n",
    "def preprocess_text_keep_punctuation(text):\n",
    "    lowered_text = to_lower_case(text)\n",
    "    initial_stopword_pass = remove_stopwords(lowered_text, stopword_set)\n",
    "    return initial_stopword_pass\n",
    "\n",
    "def remove_stopwords_two(text, stopword_set):\n",
    "    # Split by whitespace\n",
    "    split_text = text.split()\n",
    "    new_tokens = []\n",
    "    for token in split_text:\n",
    "        temp_token = token.lower()\n",
    "        if temp_token in stopword_set:\n",
    "            continue\n",
    "        new_tokens.append(token)\n",
    "    # Parse back into text\n",
    "    return ' '.join(new_tokens)\n",
    "\n",
    "# Testing dataset 2\n",
    "def preprocess_text_capitalised(text):\n",
    "    dehyphenated_text = replace_hyphens(text)\n",
    "    initial_stopword_pass = remove_stopwords_two(dehyphenated_text, stopword_set)\n",
    "    tokens = tokenise_text(initial_stopword_pass)\n",
    "    tokenised_text = ' '.join(tokens)\n",
    "    depunctuated_text = remove_punctuation(tokenised_text)\n",
    "    second_stopword_pass = remove_stopwords_two(depunctuated_text, stopword_set)\n",
    "    return second_stopword_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning training text...\n",
      "Preprocessing done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39222</th>\n",
       "      <td>4</td>\n",
       "      <td>Tennis Venus Williams Wimbledon semi finals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7603</th>\n",
       "      <td>1</td>\n",
       "      <td>Area resident Beatrice Sewell 49 affirmed fait...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18208</th>\n",
       "      <td>2</td>\n",
       "      <td>Scott Baio Loses Live TV Obama HES DUMB HES MU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9504</th>\n",
       "      <td>1</td>\n",
       "      <td>Padres broadcaster Jerry Coleman took moments ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7678</th>\n",
       "      <td>1</td>\n",
       "      <td>Two weeks hourly federal minimum wage raised 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11502</th>\n",
       "      <td>1</td>\n",
       "      <td>Revealing old fashioned small minded truly loc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23586</th>\n",
       "      <td>3</td>\n",
       "      <td>ATT Helping Feds Spy EveryoneBy Michael Maharr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39030</th>\n",
       "      <td>4</td>\n",
       "      <td>Dozens Israeli rabbis added names document cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25634</th>\n",
       "      <td>3</td>\n",
       "      <td>Brexit MatrixBy Jon Rappoport EU associated fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33810</th>\n",
       "      <td>3</td>\n",
       "      <td>Bulls Eye Smith Wesson Sales Skyrocket Maximum...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                                  1\n",
       "39222  4        Tennis Venus Williams Wimbledon semi finals\n",
       "7603   1  Area resident Beatrice Sewell 49 affirmed fait...\n",
       "18208  2  Scott Baio Loses Live TV Obama HES DUMB HES MU...\n",
       "9504   1  Padres broadcaster Jerry Coleman took moments ...\n",
       "7678   1  Two weeks hourly federal minimum wage raised 5...\n",
       "11502  1  Revealing old fashioned small minded truly loc...\n",
       "23586  3  ATT Helping Feds Spy EveryoneBy Michael Maharr...\n",
       "39030  4  Dozens Israeli rabbis added names document cal...\n",
       "25634  3  Brexit MatrixBy Jon Rappoport EU associated fi...\n",
       "33810  3  Bulls Eye Smith Wesson Sales Skyrocket Maximum..."
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Cleaning training text...')\n",
    "df[1] = df[1].map(preprocess_text_capitalised)\n",
    "print('Preprocessing done!')\n",
    "df.sample(10) # Random sample values to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning test text...\n",
      "Preprocessing done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>3</td>\n",
       "      <td>mainstream media whose editors reporters locks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>4</td>\n",
       "      <td>Police said Wednesday arrested suspect connect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>4</td>\n",
       "      <td>Results Friday French Open played clay Stade R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>2</td>\n",
       "      <td>TOP 10 Smartest Fox News BABES Hottest Decide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>2</td>\n",
       "      <td>Hillary Clinton Secrets Ed Klein List Sending ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>4</td>\n",
       "      <td>dollar edged Thursday breaking decline caused ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1</td>\n",
       "      <td>Get ready mark calendars wont want miss Soon p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2950</th>\n",
       "      <td>4</td>\n",
       "      <td>better Four Seasons end road said friend Rebec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>4</td>\n",
       "      <td>Center Timofey Mozgov 25 points 11 rebounds le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>4</td>\n",
       "      <td>comes figuring best ensconce Elizabeth Warren ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "1903  3  mainstream media whose editors reporters locks...\n",
       "2926  4  Police said Wednesday arrested suspect connect...\n",
       "2712  4  Results Friday French Open played clay Stade R...\n",
       "1080  2      TOP 10 Smartest Fox News BABES Hottest Decide\n",
       "1489  2  Hillary Clinton Secrets Ed Klein List Sending ...\n",
       "2345  4  dollar edged Thursday breaking decline caused ...\n",
       "214   1  Get ready mark calendars wont want miss Soon p...\n",
       "2950  4  better Four Seasons end road said friend Rebec...\n",
       "2671  4  Center Timofey Mozgov 25 points 11 rebounds le...\n",
       "2622  4  comes figuring best ensconce Elizabeth Warren ..."
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Cleaning test text...')\n",
    "test_df[1] = test_df[1].map(preprocess_text_capitalised)\n",
    "print('Preprocessing done!')\n",
    "test_df.sample(10) # Random sample values to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./raw_data/capitalized_fulltrain.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('./raw_data/capitalized_balancedtest.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows, Total Columns: (48854, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37119</th>\n",
       "      <td>3</td>\n",
       "      <td>Yanis Varoufakis European Constitution Economi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>1</td>\n",
       "      <td>Citing unbelievable lack depth virtually every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14217</th>\n",
       "      <td>2</td>\n",
       "      <td>Kid Rock Risks Entire Career Show America Real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31877</th>\n",
       "      <td>3</td>\n",
       "      <td>7 Things Mainstream Media Want KnowMichael Sny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26960</th>\n",
       "      <td>3</td>\n",
       "      <td>Cynthia McKinney Remarks UN International Meet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                                  1\n",
       "37119  3  Yanis Varoufakis European Constitution Economi...\n",
       "1228   1  Citing unbelievable lack depth virtually every...\n",
       "14217  2  Kid Rock Risks Entire Career Show America Real...\n",
       "31877  3  7 Things Mainstream Media Want KnowMichael Sny...\n",
       "26960  3  Cynthia McKinney Remarks UN International Meet..."
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file in\n",
    "clean_train_path = './raw_data/capitalized_fulltrain.csv'\n",
    "clean_test_path = './raw_data/capitalized_balancedtest.csv'\n",
    "clean_df = pd.read_csv(clean_train_path, header=None)\n",
    "clean_test_df = pd.read_csv(clean_test_path, header=None)\n",
    "\n",
    "print('Total rows, Total Columns: ' + str(clean_df.shape))\n",
    "clean_df.sample(5) # Random sample values to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows, Total Columns: (3000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1</td>\n",
       "      <td>covert mission designed destroy remains Al Qae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>3</td>\n",
       "      <td>take pride growing sprouts broccoli sprouts be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1</td>\n",
       "      <td>Well could big problem Right middle campaign r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>2</td>\n",
       "      <td>82 Children Recovered Federal Raid Discovered ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>4</td>\n",
       "      <td>Joe Kaeser six months new job chief financial ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "172   1  covert mission designed destroy remains Al Qae...\n",
       "2233  3  take pride growing sprouts broccoli sprouts be...\n",
       "347   1  Well could big problem Right middle campaign r...\n",
       "1092  2  82 Children Recovered Federal Raid Discovered ...\n",
       "2787  4  Joe Kaeser six months new job chief financial ..."
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Total rows, Total Columns: ' + str(clean_test_df.shape))\n",
    "clean_test_df.sample(5) # Random sample values to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US government seeing hints adversaries targeting military networks remote sabotage head Pentagon recently launched Cyber Command said first public remarks since confirmed last month potential sabotage destruction possible something must treat seriously said Gen Keith Alexander also heads National Security Agency nation largest intelligence agency Department Defense must able operate freely defend resources cyberspace Alexander spoke Thursday 300 people Center Strategic International Studies Washington remarks afterward Alexander said concerned safety computer systems used war zones concern look could happen computer clearly sabotage destruction things yet come said defend systems people able break James Lewis director CSIS Technology Public Policy Program said advanced militaries capable destroying US computer systems true four years ago true Cyber Command deal said Cyber Command launched last month Fort Meade Md created Defense Secretary Robert Gates streamline military capabilities attack defend cyberspace supported NSA intelligence capabilities Alexander stressed Command focus protecting US military 15000 computer networks oversight special Foreign Intelligence Surveillance Court Congress administration remarks aimed assuaging concerns NSA role helping protect civilian private sector networks well fears militarization cyberspace spend lot time court Congress administration oversight committees ensure know Alexander said done classified settings said including surveillance court set part effort protect Americans unwarranted government surveillance hard part ca nt go tell everybody exactly give capability may extremely useful protecting country allies said Alexander confirmation delayed months congressional concerns command role scope action operations would affect Americans privacy lack clarity rules road cyber warfare rules still debated formulated said rules engagement working Department Homeland Security private industry protecting private sector systems perhaps difficult challenge Alexander hands full hardening military systems DOD systems probed unauthorized users 6 million times day front line defenses challenge still devote much time resources dealing relatively mundane problems poorly engineered software missing patches said\n"
     ]
    }
   ],
   "source": [
    "print(clean_test_df[1][2649])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21df0356f9123b9ffe2140fcee819cd2cf32077b8756437e0847ceff6279ac46"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
