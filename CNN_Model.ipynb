{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ihDCuEbQven"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics\n",
        "from keras.preprocessing.text import Tokenizer                    \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsx7B_dCTPcI"
      },
      "source": [
        "read dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTNIln6vRiPl",
        "outputId": "2ef55507-462a-4bc2-bb3e-60a548aa1c6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "os.chdir('drive/MyDrive/CS4248 Project')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bI6cmoTMRkBA"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('raw_data/fulltrain.csv')\n",
        "train.columns =['Label', 'Text']\n",
        "test = pd.read_csv('raw_data/balancedtest.csv')\n",
        "test.columns = ['Label','Text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJikOy9iChXd",
        "outputId": "cf824214-7690-46fd-fbf4-c70e937c6c89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3    17870\n",
              "1    14046\n",
              "4     9995\n",
              "2     6942\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train['Label'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cn3_cgcoc-aG"
      },
      "outputs": [],
      "source": [
        "class2 = train.loc[train['Label'] == 2]\n",
        "class4 = train.loc[train['Label'] == 4]\n",
        "class1 = train.loc[train['Label'] == 1]\n",
        "class3 = train.loc[train['Label'] == 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU2AZR2WA0am",
        "outputId": "7fb32c80-fab2-4d7e-8a40-d77d6d6dd9fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q67vRAvkeSEj"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "import random\n",
        "shuffle_sent2 = []\n",
        "for i in range(class2.shape[0]):\n",
        "  a = sent_tokenize(class2['Text'].iloc[i])\n",
        "  random.shuffle(a)\n",
        "  a = ' '.join(a)\n",
        "  shuffle_sent2.append(a)\n",
        "class2_sent = class2.drop(\"Text\",axis =1 )\n",
        "class2_sent['Text'] = shuffle_sent2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7s574kU5kMk2"
      },
      "outputs": [],
      "source": [
        "shuffle_sent2 = []\n",
        "for i in range(class2.shape[0]):\n",
        "  a = sent_tokenize(class2['Text'].iloc[i])\n",
        "  random.shuffle(a)\n",
        "  a = ' '.join(a)\n",
        "  shuffle_sent2.append(a)\n",
        "class2_sent = class2.drop(\"Text\",axis =1 )\n",
        "class2_sent['Text'] = shuffle_sent2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDwiq-SAfh7f"
      },
      "outputs": [],
      "source": [
        "shuffle_sent4 = []\n",
        "for i in range(class4.shape[0]):\n",
        "  a = sent_tokenize(class4['Text'].iloc[i])\n",
        "  random.shuffle(a)\n",
        "  a = ' '.join(a)\n",
        "  shuffle_sent4.append(a)\n",
        "class4_sent = class4.drop(\"Text\",axis =1 )\n",
        "class4_sent['Text'] = shuffle_sent4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-KrdipiMV68"
      },
      "outputs": [],
      "source": [
        "shuffle_sent3 = []\n",
        "for i in range(class3.shape[0]):\n",
        "  a = sent_tokenize(class3['Text'].iloc[i])\n",
        "  random.shuffle(a)\n",
        "  a = ' '.join(a)\n",
        "  shuffle_sent3.append(a)\n",
        "class3_sent = class3.drop(\"Text\",axis =1 )\n",
        "class3_sent['Text'] = shuffle_sent3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQEX-a_cMa9c"
      },
      "outputs": [],
      "source": [
        "shuffle_sent1 = []\n",
        "for i in range(class1.shape[0]):\n",
        "  a = sent_tokenize(class1['Text'].iloc[i])\n",
        "  random.shuffle(a)\n",
        "  a = ' '.join(a)\n",
        "  shuffle_sent1.append(a)\n",
        "class1_sent = class1.drop(\"Text\",axis =1 )\n",
        "class1_sent['Text'] = shuffle_sent1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOpREU0QlNEZ"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "shuffle_word2 = []\n",
        "for i in range(class2.shape[0]):\n",
        "  a = word_tokenize(class2['Text'].iloc[i])\n",
        "  random.shuffle(a)\n",
        "  a = ' '.join(a)\n",
        "  shuffle_word2.append(a)\n",
        "class2_word = class2.drop(\"Text\",axis =1 )\n",
        "class2_word['Text'] = shuffle_word2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUAX7irdl6dz"
      },
      "outputs": [],
      "source": [
        "train = train.append(class4_sent.sample(n=8500))\n",
        "train = train.append(class2_sent.sample(n=6000))\n",
        "train = train.append(class2_word.sample(n=5500))\n",
        "train = train.append(class3_sent.sample(n=500))\n",
        "train = train.append(class1_sent.sample(n=4000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cojroIOkmrhS",
        "outputId": "3f0ac894-b1b6-46d2-85c8-15905ac35267"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4    18495\n",
              "2    18442\n",
              "3    18370\n",
              "1    18046\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train['Label'].value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL_pBzvdd5jU"
      },
      "source": [
        "Set weight for each type to make them balanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afwrhBAdeA3L"
      },
      "source": [
        "The original train text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urJDoMW6TZ1I"
      },
      "outputs": [],
      "source": [
        "train_x = train['Text'].values\n",
        "test_x = test['Text'].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5WDrCrS2ocU"
      },
      "source": [
        "### create dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp5zmn8CduDS"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(train_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DarkVQpYeIwZ"
      },
      "outputs": [],
      "source": [
        "X_train = tokenizer.texts_to_sequences(train_x)\n",
        "X_test = tokenizer.texts_to_sequences(test_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MvICp2HeoXn"
      },
      "source": [
        "Padding data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQd8T5K_W-Ml"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1                          \n",
        "\n",
        "maxlen = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t89uNBDUeqzM"
      },
      "source": [
        "word2vec embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_fAtaEYXwjc"
      },
      "outputs": [],
      "source": [
        "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
        "    vocab_size = len(word_index) + 1  \n",
        "    # Adding again 1 because of reserved 0 index\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "    with open(filepath) as f:\n",
        "        for line in f:\n",
        "            word, *vector = line.split()\n",
        "            if word in word_index:\n",
        "                idx = word_index[word] \n",
        "                embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "    return embedding_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Hj2zaFSeugU"
      },
      "source": [
        "Golve word2vec package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nA5kkrMMfwqr"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 200\n",
        "embedding_matrix = create_embedding_matrix('glove.6B.200d.txt' ,\n",
        "                                            tokenizer.word_index,  \n",
        "                                            embedding_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_JxGPnVexjE"
      },
      "source": [
        "Create label for model, train_y.shape[48853,4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_b03a-98s9-"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc_df = enc.fit_transform(train[['Label']]).toarray()\n",
        "enc_df2 = enc.fit_transform(test[['Label']]).toarray()\n",
        "train_y = pd.DataFrame(enc_df)\n",
        "test_y = pd.DataFrame(enc_df2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7Xs5FxRe9M0"
      },
      "source": [
        "### CNN model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0qcihqhg2Ep",
        "outputId": "68abf3dc-ccf7-4125-f69c-cffa101f5e72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1605/1605 [==============================] - 104s 57ms/step - loss: 1.2646 - precision: 0.8330 - recall: 0.5223 - accuracy: 0.6621 - val_loss: 1.0982 - val_precision: 0.8196 - val_recall: 0.6984 - val_accuracy: 0.7652\n",
            "Epoch 2/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.8074 - precision: 0.9057 - recall: 0.8710 - accuracy: 0.8882 - val_loss: 0.9729 - val_precision: 0.8736 - val_recall: 0.8065 - val_accuracy: 0.8453\n",
            "Epoch 3/100\n",
            "1605/1605 [==============================] - 91s 56ms/step - loss: 0.7450 - precision: 0.9267 - recall: 0.9042 - accuracy: 0.9147 - val_loss: 0.9036 - val_precision: 0.8644 - val_recall: 0.8056 - val_accuracy: 0.8351\n",
            "Epoch 4/100\n",
            "1605/1605 [==============================] - 90s 56ms/step - loss: 0.6940 - precision: 0.9338 - recall: 0.9157 - accuracy: 0.9247 - val_loss: 1.0503 - val_precision: 0.7868 - val_recall: 0.7459 - val_accuracy: 0.7671\n",
            "Epoch 5/100\n",
            "1605/1605 [==============================] - 90s 56ms/step - loss: 0.6492 - precision: 0.9369 - recall: 0.9213 - accuracy: 0.9285 - val_loss: 0.8243 - val_precision: 0.8928 - val_recall: 0.8594 - val_accuracy: 0.8753\n",
            "Epoch 6/100\n",
            "1605/1605 [==============================] - 93s 58ms/step - loss: 0.6071 - precision: 0.9430 - recall: 0.9297 - accuracy: 0.9361 - val_loss: 0.7368 - val_precision: 0.8848 - val_recall: 0.8460 - val_accuracy: 0.8670\n",
            "Epoch 7/100\n",
            "1605/1605 [==============================] - 90s 56ms/step - loss: 0.5688 - precision: 0.9450 - recall: 0.9325 - accuracy: 0.9383 - val_loss: 1.1542 - val_precision: 0.7420 - val_recall: 0.6919 - val_accuracy: 0.7160\n",
            "Epoch 8/100\n",
            "1605/1605 [==============================] - 90s 56ms/step - loss: 0.5501 - precision: 0.9448 - recall: 0.9329 - accuracy: 0.9390 - val_loss: 0.8236 - val_precision: 0.8636 - val_recall: 0.8350 - val_accuracy: 0.8480\n",
            "Epoch 9/100\n",
            "1605/1605 [==============================] - 90s 56ms/step - loss: 0.5209 - precision: 0.9472 - recall: 0.9360 - accuracy: 0.9412 - val_loss: 0.7108 - val_precision: 0.8825 - val_recall: 0.8418 - val_accuracy: 0.8618\n",
            "Epoch 10/100\n",
            "1605/1605 [==============================] - 91s 56ms/step - loss: 0.4978 - precision: 0.9478 - recall: 0.9374 - accuracy: 0.9422 - val_loss: 0.7503 - val_precision: 0.8607 - val_recall: 0.8233 - val_accuracy: 0.8415\n",
            "Epoch 11/100\n",
            "1605/1605 [==============================] - 90s 56ms/step - loss: 0.4894 - precision: 0.9472 - recall: 0.9368 - accuracy: 0.9421 - val_loss: 0.7449 - val_precision: 0.8721 - val_recall: 0.8354 - val_accuracy: 0.8537\n",
            "Epoch 12/100\n",
            "1605/1605 [==============================] - 90s 56ms/step - loss: 0.4728 - precision: 0.9500 - recall: 0.9402 - accuracy: 0.9448 - val_loss: 0.8006 - val_precision: 0.8475 - val_recall: 0.8116 - val_accuracy: 0.8294\n",
            "Epoch 13/100\n",
            "1605/1605 [==============================] - 90s 56ms/step - loss: 0.4572 - precision: 0.9527 - recall: 0.9432 - accuracy: 0.9477 - val_loss: 0.6545 - val_precision: 0.8890 - val_recall: 0.8629 - val_accuracy: 0.8755\n",
            "Epoch 14/100\n",
            "1605/1605 [==============================] - 89s 55ms/step - loss: 0.4555 - precision: 0.9519 - recall: 0.9436 - accuracy: 0.9473 - val_loss: 0.6461 - val_precision: 0.8951 - val_recall: 0.8693 - val_accuracy: 0.8817\n",
            "Epoch 15/100\n",
            "1605/1605 [==============================] - 91s 57ms/step - loss: 0.4510 - precision: 0.9524 - recall: 0.9438 - accuracy: 0.9478 - val_loss: 0.6139 - val_precision: 0.8960 - val_recall: 0.8741 - val_accuracy: 0.8850\n",
            "Epoch 16/100\n",
            "1605/1605 [==============================] - 90s 56ms/step - loss: 0.4357 - precision: 0.9544 - recall: 0.9464 - accuracy: 0.9500 - val_loss: 0.6755 - val_precision: 0.8597 - val_recall: 0.8307 - val_accuracy: 0.8451\n",
            "Epoch 17/100\n",
            "1605/1605 [==============================] - 89s 56ms/step - loss: 0.4243 - precision: 0.9547 - recall: 0.9467 - accuracy: 0.9508 - val_loss: 0.6835 - val_precision: 0.8732 - val_recall: 0.8535 - val_accuracy: 0.8632\n",
            "Epoch 18/100\n",
            "1605/1605 [==============================] - 89s 56ms/step - loss: 0.4221 - precision: 0.9548 - recall: 0.9462 - accuracy: 0.9506 - val_loss: 0.6909 - val_precision: 0.8712 - val_recall: 0.8525 - val_accuracy: 0.8611\n",
            "Epoch 19/100\n",
            "1605/1605 [==============================] - 91s 57ms/step - loss: 0.4091 - precision: 0.9572 - recall: 0.9498 - accuracy: 0.9534 - val_loss: 0.6459 - val_precision: 0.8797 - val_recall: 0.8572 - val_accuracy: 0.8676\n",
            "Epoch 20/100\n",
            "1605/1605 [==============================] - 89s 55ms/step - loss: 0.4099 - precision: 0.9578 - recall: 0.9504 - accuracy: 0.9535 - val_loss: 0.5670 - val_precision: 0.9045 - val_recall: 0.8858 - val_accuracy: 0.8951\n",
            "Epoch 21/100\n",
            "1605/1605 [==============================] - 91s 57ms/step - loss: 0.3998 - precision: 0.9577 - recall: 0.9505 - accuracy: 0.9539 - val_loss: 0.7139 - val_precision: 0.8596 - val_recall: 0.8383 - val_accuracy: 0.8496\n",
            "Epoch 22/100\n",
            "1605/1605 [==============================] - 94s 58ms/step - loss: 0.3914 - precision: 0.9584 - recall: 0.9513 - accuracy: 0.9545 - val_loss: 0.7275 - val_precision: 0.8586 - val_recall: 0.8373 - val_accuracy: 0.8465\n",
            "Epoch 23/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.3930 - precision: 0.9579 - recall: 0.9510 - accuracy: 0.9543 - val_loss: 0.7560 - val_precision: 0.8334 - val_recall: 0.8145 - val_accuracy: 0.8235\n",
            "Epoch 24/100\n",
            "1605/1605 [==============================] - 90s 56ms/step - loss: 0.3912 - precision: 0.9584 - recall: 0.9516 - accuracy: 0.9546 - val_loss: 0.5871 - val_precision: 0.8972 - val_recall: 0.8801 - val_accuracy: 0.8891\n",
            "Epoch 25/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.3779 - precision: 0.9598 - recall: 0.9527 - accuracy: 0.9560 - val_loss: 0.5472 - val_precision: 0.9079 - val_recall: 0.8926 - val_accuracy: 0.9001\n",
            "Epoch 26/100\n",
            "1605/1605 [==============================] - 90s 56ms/step - loss: 0.3815 - precision: 0.9593 - recall: 0.9527 - accuracy: 0.9558 - val_loss: 0.7141 - val_precision: 0.8597 - val_recall: 0.8381 - val_accuracy: 0.8483\n",
            "Epoch 27/100\n",
            "1605/1605 [==============================] - 89s 56ms/step - loss: 0.3726 - precision: 0.9614 - recall: 0.9556 - accuracy: 0.9586 - val_loss: 0.8617 - val_precision: 0.8271 - val_recall: 0.8034 - val_accuracy: 0.8143\n",
            "Epoch 28/100\n",
            "1605/1605 [==============================] - 89s 55ms/step - loss: 0.3793 - precision: 0.9595 - recall: 0.9533 - accuracy: 0.9560 - val_loss: 0.6087 - val_precision: 0.8885 - val_recall: 0.8725 - val_accuracy: 0.8804\n",
            "Epoch 29/100\n",
            "1605/1605 [==============================] - 89s 56ms/step - loss: 0.3676 - precision: 0.9627 - recall: 0.9568 - accuracy: 0.9595 - val_loss: 0.8017 - val_precision: 0.8295 - val_recall: 0.8069 - val_accuracy: 0.8175\n",
            "Epoch 30/100\n",
            "1605/1605 [==============================] - 91s 57ms/step - loss: 0.3690 - precision: 0.9621 - recall: 0.9559 - accuracy: 0.9588 - val_loss: 0.5100 - val_precision: 0.9122 - val_recall: 0.9000 - val_accuracy: 0.9049\n",
            "Epoch 31/100\n",
            "1605/1605 [==============================] - 91s 57ms/step - loss: 0.3658 - precision: 0.9619 - recall: 0.9563 - accuracy: 0.9586 - val_loss: 0.6357 - val_precision: 0.8734 - val_recall: 0.8539 - val_accuracy: 0.8634\n",
            "Epoch 32/100\n",
            "1605/1605 [==============================] - 90s 56ms/step - loss: 0.3591 - precision: 0.9623 - recall: 0.9571 - accuracy: 0.9595 - val_loss: 0.6616 - val_precision: 0.8657 - val_recall: 0.8453 - val_accuracy: 0.8541\n",
            "Epoch 33/100\n",
            "1605/1605 [==============================] - 90s 56ms/step - loss: 0.3576 - precision: 0.9624 - recall: 0.9565 - accuracy: 0.9593 - val_loss: 0.5738 - val_precision: 0.9004 - val_recall: 0.8858 - val_accuracy: 0.8920\n",
            "Epoch 34/100\n",
            "1605/1605 [==============================] - 91s 57ms/step - loss: 0.3560 - precision: 0.9622 - recall: 0.9565 - accuracy: 0.9592 - val_loss: 0.5806 - val_precision: 0.8931 - val_recall: 0.8770 - val_accuracy: 0.8845\n",
            "Epoch 35/100\n",
            "1605/1605 [==============================] - 91s 57ms/step - loss: 0.3484 - precision: 0.9626 - recall: 0.9570 - accuracy: 0.9597 - val_loss: 0.7478 - val_precision: 0.8454 - val_recall: 0.8216 - val_accuracy: 0.8316\n",
            "Epoch 36/100\n",
            "1605/1605 [==============================] - 90s 56ms/step - loss: 0.3483 - precision: 0.9615 - recall: 0.9555 - accuracy: 0.9585 - val_loss: 0.5279 - val_precision: 0.9054 - val_recall: 0.8891 - val_accuracy: 0.8973\n",
            "Epoch 37/100\n",
            "1605/1605 [==============================] - 93s 58ms/step - loss: 0.3441 - precision: 0.9610 - recall: 0.9544 - accuracy: 0.9574 - val_loss: 0.6009 - val_precision: 0.8841 - val_recall: 0.8706 - val_accuracy: 0.8761\n",
            "Epoch 38/100\n",
            "1605/1605 [==============================] - 89s 56ms/step - loss: 0.3399 - precision: 0.9599 - recall: 0.9541 - accuracy: 0.9569 - val_loss: 0.5617 - val_precision: 0.8899 - val_recall: 0.8791 - val_accuracy: 0.8840\n",
            "Epoch 39/100\n",
            "1605/1605 [==============================] - 89s 56ms/step - loss: 0.3321 - precision: 0.9616 - recall: 0.9559 - accuracy: 0.9588 - val_loss: 0.7010 - val_precision: 0.8514 - val_recall: 0.8345 - val_accuracy: 0.8416\n",
            "Epoch 40/100\n",
            "1605/1605 [==============================] - 91s 57ms/step - loss: 0.3345 - precision: 0.9618 - recall: 0.9562 - accuracy: 0.9588 - val_loss: 0.5826 - val_precision: 0.8814 - val_recall: 0.8629 - val_accuracy: 0.8712\n",
            "Epoch 41/100\n",
            "1605/1605 [==============================] - 93s 58ms/step - loss: 0.3335 - precision: 0.9622 - recall: 0.9562 - accuracy: 0.9585 - val_loss: 0.5379 - val_precision: 0.8937 - val_recall: 0.8785 - val_accuracy: 0.8852\n",
            "Epoch 42/100\n",
            "1605/1605 [==============================] - 90s 56ms/step - loss: 0.3394 - precision: 0.9615 - recall: 0.9557 - accuracy: 0.9582 - val_loss: 0.5215 - val_precision: 0.9061 - val_recall: 0.8929 - val_accuracy: 0.8990\n",
            "Epoch 43/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.3272 - precision: 0.9627 - recall: 0.9569 - accuracy: 0.9597 - val_loss: 0.7157 - val_precision: 0.8456 - val_recall: 0.8236 - val_accuracy: 0.8340\n",
            "Epoch 44/100\n",
            "1605/1605 [==============================] - 91s 57ms/step - loss: 0.3275 - precision: 0.9633 - recall: 0.9582 - accuracy: 0.9605 - val_loss: 0.6072 - val_precision: 0.8814 - val_recall: 0.8644 - val_accuracy: 0.8725\n",
            "Epoch 45/100\n",
            "1605/1605 [==============================] - 91s 57ms/step - loss: 0.3279 - precision: 0.9636 - recall: 0.9583 - accuracy: 0.9610 - val_loss: 0.7670 - val_precision: 0.8399 - val_recall: 0.8188 - val_accuracy: 0.8282\n",
            "Epoch 46/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.3257 - precision: 0.9641 - recall: 0.9585 - accuracy: 0.9609 - val_loss: 0.5486 - val_precision: 0.8942 - val_recall: 0.8791 - val_accuracy: 0.8866\n",
            "Epoch 47/100\n",
            "1605/1605 [==============================] - 92s 58ms/step - loss: 0.3250 - precision: 0.9637 - recall: 0.9579 - accuracy: 0.9606 - val_loss: 0.5289 - val_precision: 0.9002 - val_recall: 0.8854 - val_accuracy: 0.8937\n",
            "Epoch 48/100\n",
            "1605/1605 [==============================] - 91s 57ms/step - loss: 0.3228 - precision: 0.9648 - recall: 0.9599 - accuracy: 0.9623 - val_loss: 0.5901 - val_precision: 0.8894 - val_recall: 0.8770 - val_accuracy: 0.8821\n",
            "Epoch 49/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.3190 - precision: 0.9657 - recall: 0.9608 - accuracy: 0.9630 - val_loss: 0.5320 - val_precision: 0.8999 - val_recall: 0.8882 - val_accuracy: 0.8942\n",
            "Epoch 50/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.3207 - precision: 0.9670 - recall: 0.9623 - accuracy: 0.9643 - val_loss: 0.5855 - val_precision: 0.8871 - val_recall: 0.8728 - val_accuracy: 0.8787\n",
            "Epoch 51/100\n",
            "1605/1605 [==============================] - 93s 58ms/step - loss: 0.3188 - precision: 0.9660 - recall: 0.9608 - accuracy: 0.9634 - val_loss: 0.6164 - val_precision: 0.8814 - val_recall: 0.8666 - val_accuracy: 0.8732\n",
            "Epoch 52/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.3136 - precision: 0.9673 - recall: 0.9625 - accuracy: 0.9648 - val_loss: 0.5310 - val_precision: 0.9060 - val_recall: 0.8948 - val_accuracy: 0.9006\n",
            "Epoch 53/100\n",
            "1605/1605 [==============================] - 94s 59ms/step - loss: 0.3172 - precision: 0.9661 - recall: 0.9613 - accuracy: 0.9637 - val_loss: 0.6716 - val_precision: 0.8622 - val_recall: 0.8464 - val_accuracy: 0.8540\n",
            "Epoch 54/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.3176 - precision: 0.9662 - recall: 0.9616 - accuracy: 0.9638 - val_loss: 0.5182 - val_precision: 0.9146 - val_recall: 0.9056 - val_accuracy: 0.9102\n",
            "Epoch 55/100\n",
            "1605/1605 [==============================] - 94s 59ms/step - loss: 0.3122 - precision: 0.9680 - recall: 0.9634 - accuracy: 0.9656 - val_loss: 0.5400 - val_precision: 0.8931 - val_recall: 0.8794 - val_accuracy: 0.8861\n",
            "Epoch 56/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.3212 - precision: 0.9659 - recall: 0.9612 - accuracy: 0.9632 - val_loss: 0.5699 - val_precision: 0.8925 - val_recall: 0.8789 - val_accuracy: 0.8850\n",
            "Epoch 57/100\n",
            "1605/1605 [==============================] - 93s 58ms/step - loss: 0.3155 - precision: 0.9665 - recall: 0.9621 - accuracy: 0.9641 - val_loss: 0.5421 - val_precision: 0.9004 - val_recall: 0.8889 - val_accuracy: 0.8939\n",
            "Epoch 58/100\n",
            "1605/1605 [==============================] - 92s 58ms/step - loss: 0.3089 - precision: 0.9681 - recall: 0.9636 - accuracy: 0.9655 - val_loss: 0.5730 - val_precision: 0.8977 - val_recall: 0.8846 - val_accuracy: 0.8909\n",
            "Epoch 59/100\n",
            "1605/1605 [==============================] - 94s 59ms/step - loss: 0.3107 - precision: 0.9674 - recall: 0.9635 - accuracy: 0.9652 - val_loss: 0.6803 - val_precision: 0.8579 - val_recall: 0.8439 - val_accuracy: 0.8501\n",
            "Epoch 60/100\n",
            "1605/1605 [==============================] - 94s 58ms/step - loss: 0.3025 - precision: 0.9689 - recall: 0.9649 - accuracy: 0.9666 - val_loss: 0.5610 - val_precision: 0.8969 - val_recall: 0.8851 - val_accuracy: 0.8902\n",
            "Epoch 61/100\n",
            "1605/1605 [==============================] - 93s 58ms/step - loss: 0.3054 - precision: 0.9684 - recall: 0.9642 - accuracy: 0.9661 - val_loss: 0.6982 - val_precision: 0.8607 - val_recall: 0.8464 - val_accuracy: 0.8529\n",
            "Epoch 62/100\n",
            "1605/1605 [==============================] - 92s 58ms/step - loss: 0.3088 - precision: 0.9679 - recall: 0.9638 - accuracy: 0.9656 - val_loss: 0.5244 - val_precision: 0.8998 - val_recall: 0.8856 - val_accuracy: 0.8916\n",
            "Epoch 63/100\n",
            "1605/1605 [==============================] - 94s 59ms/step - loss: 0.3055 - precision: 0.9690 - recall: 0.9645 - accuracy: 0.9665 - val_loss: 0.5764 - val_precision: 0.8888 - val_recall: 0.8751 - val_accuracy: 0.8819\n",
            "Epoch 64/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.3036 - precision: 0.9686 - recall: 0.9641 - accuracy: 0.9662 - val_loss: 0.5673 - val_precision: 0.8858 - val_recall: 0.8703 - val_accuracy: 0.8779\n",
            "Epoch 65/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.3022 - precision: 0.9687 - recall: 0.9645 - accuracy: 0.9665 - val_loss: 0.6569 - val_precision: 0.8670 - val_recall: 0.8513 - val_accuracy: 0.8579\n",
            "Epoch 66/100\n",
            "1605/1605 [==============================] - 94s 58ms/step - loss: 0.3036 - precision: 0.9693 - recall: 0.9653 - accuracy: 0.9672 - val_loss: 0.6738 - val_precision: 0.8674 - val_recall: 0.8534 - val_accuracy: 0.8589\n",
            "Epoch 67/100\n",
            "1605/1605 [==============================] - 92s 58ms/step - loss: 0.2979 - precision: 0.9699 - recall: 0.9658 - accuracy: 0.9673 - val_loss: 0.6526 - val_precision: 0.8659 - val_recall: 0.8523 - val_accuracy: 0.8584\n",
            "Epoch 68/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.2981 - precision: 0.9697 - recall: 0.9657 - accuracy: 0.9676 - val_loss: 0.8322 - val_precision: 0.8241 - val_recall: 0.8068 - val_accuracy: 0.8144\n",
            "Epoch 69/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.3031 - precision: 0.9682 - recall: 0.9638 - accuracy: 0.9656 - val_loss: 0.6890 - val_precision: 0.8531 - val_recall: 0.8364 - val_accuracy: 0.8442\n",
            "Epoch 70/100\n",
            "1605/1605 [==============================] - 92s 58ms/step - loss: 0.2951 - precision: 0.9699 - recall: 0.9655 - accuracy: 0.9674 - val_loss: 0.5961 - val_precision: 0.8806 - val_recall: 0.8672 - val_accuracy: 0.8727\n",
            "Epoch 71/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.2987 - precision: 0.9693 - recall: 0.9650 - accuracy: 0.9670 - val_loss: 0.6660 - val_precision: 0.8608 - val_recall: 0.8439 - val_accuracy: 0.8516\n",
            "Epoch 72/100\n",
            "1605/1605 [==============================] - 93s 58ms/step - loss: 0.2971 - precision: 0.9696 - recall: 0.9656 - accuracy: 0.9674 - val_loss: 0.4725 - val_precision: 0.9131 - val_recall: 0.9028 - val_accuracy: 0.9074\n",
            "Epoch 73/100\n",
            "1605/1605 [==============================] - 92s 58ms/step - loss: 0.2899 - precision: 0.9693 - recall: 0.9650 - accuracy: 0.9670 - val_loss: 0.5948 - val_precision: 0.8809 - val_recall: 0.8654 - val_accuracy: 0.8723\n",
            "Epoch 74/100\n",
            "1605/1605 [==============================] - 92s 58ms/step - loss: 0.2914 - precision: 0.9684 - recall: 0.9644 - accuracy: 0.9663 - val_loss: 0.5457 - val_precision: 0.8905 - val_recall: 0.8783 - val_accuracy: 0.8843\n",
            "Epoch 75/100\n",
            "1605/1605 [==============================] - 92s 58ms/step - loss: 0.2938 - precision: 0.9693 - recall: 0.9651 - accuracy: 0.9671 - val_loss: 0.5279 - val_precision: 0.9021 - val_recall: 0.8917 - val_accuracy: 0.8963\n",
            "Epoch 76/100\n",
            "1605/1605 [==============================] - 93s 58ms/step - loss: 0.2926 - precision: 0.9687 - recall: 0.9645 - accuracy: 0.9665 - val_loss: 0.5793 - val_precision: 0.8819 - val_recall: 0.8686 - val_accuracy: 0.8745\n",
            "Epoch 77/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.2842 - precision: 0.9713 - recall: 0.9668 - accuracy: 0.9690 - val_loss: 0.5300 - val_precision: 0.8995 - val_recall: 0.8891 - val_accuracy: 0.8938\n",
            "Epoch 78/100\n",
            "1605/1605 [==============================] - 94s 59ms/step - loss: 0.2964 - precision: 0.9676 - recall: 0.9634 - accuracy: 0.9656 - val_loss: 0.5299 - val_precision: 0.9033 - val_recall: 0.8882 - val_accuracy: 0.8957\n",
            "Epoch 79/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.2851 - precision: 0.9707 - recall: 0.9669 - accuracy: 0.9688 - val_loss: 0.6052 - val_precision: 0.8807 - val_recall: 0.8668 - val_accuracy: 0.8735\n",
            "Epoch 80/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.2885 - precision: 0.9693 - recall: 0.9653 - accuracy: 0.9672 - val_loss: 0.6331 - val_precision: 0.8705 - val_recall: 0.8539 - val_accuracy: 0.8617\n",
            "Epoch 81/100\n",
            "1605/1605 [==============================] - 93s 58ms/step - loss: 0.2834 - precision: 0.9713 - recall: 0.9673 - accuracy: 0.9692 - val_loss: 0.5503 - val_precision: 0.8885 - val_recall: 0.8756 - val_accuracy: 0.8816\n",
            "Epoch 82/100\n",
            "1605/1605 [==============================] - 92s 58ms/step - loss: 0.2856 - precision: 0.9705 - recall: 0.9663 - accuracy: 0.9683 - val_loss: 0.5991 - val_precision: 0.8755 - val_recall: 0.8610 - val_accuracy: 0.8680\n",
            "Epoch 83/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.2825 - precision: 0.9707 - recall: 0.9667 - accuracy: 0.9684 - val_loss: 0.5486 - val_precision: 0.8899 - val_recall: 0.8772 - val_accuracy: 0.8824\n",
            "Epoch 84/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.2839 - precision: 0.9706 - recall: 0.9665 - accuracy: 0.9685 - val_loss: 0.5115 - val_precision: 0.8988 - val_recall: 0.8875 - val_accuracy: 0.8929\n",
            "Epoch 85/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.2846 - precision: 0.9703 - recall: 0.9668 - accuracy: 0.9685 - val_loss: 0.5668 - val_precision: 0.8953 - val_recall: 0.8850 - val_accuracy: 0.8897\n",
            "Epoch 86/100\n",
            "1605/1605 [==============================] - 91s 57ms/step - loss: 0.2834 - precision: 0.9711 - recall: 0.9675 - accuracy: 0.9690 - val_loss: 0.6262 - val_precision: 0.8760 - val_recall: 0.8598 - val_accuracy: 0.8670\n",
            "Epoch 87/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.2808 - precision: 0.9722 - recall: 0.9682 - accuracy: 0.9702 - val_loss: 0.5623 - val_precision: 0.8857 - val_recall: 0.8719 - val_accuracy: 0.8781\n",
            "Epoch 88/100\n",
            "1605/1605 [==============================] - 93s 58ms/step - loss: 0.2785 - precision: 0.9717 - recall: 0.9679 - accuracy: 0.9696 - val_loss: 0.5241 - val_precision: 0.9009 - val_recall: 0.8874 - val_accuracy: 0.8935\n",
            "Epoch 89/100\n",
            "1605/1605 [==============================] - 91s 57ms/step - loss: 0.2808 - precision: 0.9719 - recall: 0.9679 - accuracy: 0.9697 - val_loss: 0.5390 - val_precision: 0.8970 - val_recall: 0.8836 - val_accuracy: 0.8897\n",
            "Epoch 90/100\n",
            "1605/1605 [==============================] - 91s 57ms/step - loss: 0.2834 - precision: 0.9712 - recall: 0.9674 - accuracy: 0.9693 - val_loss: 0.5194 - val_precision: 0.8953 - val_recall: 0.8837 - val_accuracy: 0.8887\n",
            "Epoch 91/100\n",
            "1605/1605 [==============================] - 91s 57ms/step - loss: 0.2759 - precision: 0.9714 - recall: 0.9676 - accuracy: 0.9694 - val_loss: 0.5440 - val_precision: 0.8928 - val_recall: 0.8823 - val_accuracy: 0.8872\n",
            "Epoch 92/100\n",
            "1605/1605 [==============================] - 91s 57ms/step - loss: 0.2767 - precision: 0.9717 - recall: 0.9684 - accuracy: 0.9697 - val_loss: 0.5309 - val_precision: 0.9024 - val_recall: 0.8926 - val_accuracy: 0.8973\n",
            "Epoch 93/100\n",
            "1605/1605 [==============================] - 91s 57ms/step - loss: 0.2827 - precision: 0.9707 - recall: 0.9667 - accuracy: 0.9685 - val_loss: 0.7563 - val_precision: 0.8405 - val_recall: 0.8224 - val_accuracy: 0.8309\n",
            "Epoch 94/100\n",
            "1605/1605 [==============================] - 94s 58ms/step - loss: 0.2833 - precision: 0.9705 - recall: 0.9660 - accuracy: 0.9682 - val_loss: 0.5412 - val_precision: 0.8923 - val_recall: 0.8788 - val_accuracy: 0.8847\n",
            "Epoch 95/100\n",
            "1605/1605 [==============================] - 91s 57ms/step - loss: 0.2752 - precision: 0.9713 - recall: 0.9673 - accuracy: 0.9691 - val_loss: 0.6146 - val_precision: 0.8716 - val_recall: 0.8566 - val_accuracy: 0.8634\n",
            "Epoch 96/100\n",
            "1605/1605 [==============================] - 94s 59ms/step - loss: 0.2774 - precision: 0.9708 - recall: 0.9669 - accuracy: 0.9688 - val_loss: 0.6773 - val_precision: 0.8557 - val_recall: 0.8384 - val_accuracy: 0.8456\n",
            "Epoch 97/100\n",
            "1605/1605 [==============================] - 94s 59ms/step - loss: 0.2737 - precision: 0.9713 - recall: 0.9676 - accuracy: 0.9695 - val_loss: 0.5686 - val_precision: 0.8820 - val_recall: 0.8671 - val_accuracy: 0.8738\n",
            "Epoch 98/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.2811 - precision: 0.9690 - recall: 0.9649 - accuracy: 0.9668 - val_loss: 0.5269 - val_precision: 0.9026 - val_recall: 0.8893 - val_accuracy: 0.8952\n",
            "Epoch 99/100\n",
            "1605/1605 [==============================] - 92s 58ms/step - loss: 0.2732 - precision: 0.9713 - recall: 0.9672 - accuracy: 0.9691 - val_loss: 0.5624 - val_precision: 0.8999 - val_recall: 0.8899 - val_accuracy: 0.8948\n",
            "Epoch 100/100\n",
            "1605/1605 [==============================] - 92s 57ms/step - loss: 0.2714 - precision: 0.9721 - recall: 0.9684 - accuracy: 0.9706 - val_loss: 0.5682 - val_precision: 0.8776 - val_recall: 0.8641 - val_accuracy: 0.8694\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from sklearn.metrics import fbeta_score\n",
        "embedding_dim = 200\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "model.add(layers.GaussianNoise(stddev=0.2))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu',kernel_regularizer=tf.keras.regularizers.l2( l2 = 0.1)))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(4, activation='softmax'))\n",
        "model.compile(optimizer='Adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"CNN_model.h5\", save_best_only=True, monitor='val_accuracy', verbose=1)\n",
        "cnn = model.fit(X_train, train_y,\n",
        "                    epochs=15,\n",
        "                    shuffle = True,\n",
        "                    validation_data=(X_test, test_y),\n",
        "                    batch_size=32,\n",
        "                    callbacks=[model_checkpoint])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "GPU RNN .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
