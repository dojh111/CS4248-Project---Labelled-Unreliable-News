{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN LSTM Text Classificaiton model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string                           # For removal of punctuation\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# os.chdir('drive/MyDrive/School Work/CS4248/News Labelling Project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data into pd dataframes, data viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Total rows, Total Columns: (48854, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13640</th>\n",
       "      <td>1</td>\n",
       "      <td>This week Brooke Alvarez's new book 'Alone In ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>1</td>\n",
       "      <td>It's always hard to decide what to wear when y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>1</td>\n",
       "      <td>Speaking at its annual summit held around the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22059</th>\n",
       "      <td>3</td>\n",
       "      <td>Kratom Ban No Longer 9/30: DEA Says Timetable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10584</th>\n",
       "      <td>1</td>\n",
       "      <td>Citing its seductive warmth and utter remove f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                                  1\n",
       "13640  1  This week Brooke Alvarez's new book 'Alone In ...\n",
       "3611   1  It's always hard to decide what to wear when y...\n",
       "2613   1  Speaking at its annual summit held around the ...\n",
       "22059  3  Kratom Ban No Longer 9/30: DEA Says Timetable ...\n",
       "10584  1  Citing its seductive warmth and utter remove f..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file in\n",
    "train_path = './raw_data/fulltrain.csv'\n",
    "test_path = './raw_data/balancedtest.csv'\n",
    "df = pd.read_csv(train_path, header=None)\n",
    "\n",
    "print(type(df))\n",
    "\n",
    "# Samples, number of columns, 0 = labels, column 1 = text\n",
    "print('Total rows, Total Columns: ' + str(df.shape))\n",
    "df.sample(5) # Random sample values to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satire: 14047\n",
      "Hoax: 6942\n",
      "Propaganda: 17870\n",
      "Reliable News: 9995\n",
      "3    17870\n",
      "1    14047\n",
      "4     9995\n",
      "2     6942\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get number of labels for each task\n",
    "classes = ['Satire', 'Hoax', 'Propaganda', 'Reliable News']\n",
    "label_numbers = [1,2,3,4]\n",
    "\n",
    "for label in label_numbers:\n",
    "    print(classes[label-1] + ': ' + str((df[0] == label).sum()))\n",
    "print(df[0].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows, Total Columns:       0                                                  1\n",
      "0     1  When so many actors seem content to churn out ...\n",
      "1     1   In what football insiders are calling an unex...\n",
      "2     1  In a freak accident following Game 3 of the N....\n",
      "3     1  North Koreas official news agency announced to...\n",
      "4     1  The former Alaska Governor Sarah Palin would b...\n",
      "...  ..                                                ...\n",
      "2995  4  The Air Force mistakenly gave rival companies ...\n",
      "2996  4  The United Nations climate chief on Friday cha...\n",
      "2997  4  River Plate midfielder Diego Buonanotte has un...\n",
      "2998  4  Lawmakers were on the brink Tuesday of exempti...\n",
      "2999  4  The Pentagon, which is processing bids on a ne...\n",
      "\n",
      "[3000 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>3</td>\n",
       "      <td>California 'raw milk man' James Stewart, who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>3</td>\n",
       "      <td>In the wake of revelations - thanks in every ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>3</td>\n",
       "      <td>A major manufacturer of antibiotic and arseni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>3</td>\n",
       "      <td>In a naked attempt to shred the Constitution'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>2</td>\n",
       "      <td>Easy Way to Make 200 Grand A Year This is no j...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "1957  3   California 'raw milk man' James Stewart, who ...\n",
       "1786  3   In the wake of revelations - thanks in every ...\n",
       "1867  3   A major manufacturer of antibiotic and arseni...\n",
       "2175  3   In a naked attempt to shred the Constitution'...\n",
       "889   2  Easy Way to Make 200 Grand A Year This is no j..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_path, header=None)\n",
    "\n",
    "# Samples, number of columns, 0 = labels, column 1 = text\n",
    "print('Total rows, Total Columns: ' + str(test_df))\n",
    "test_df.sample(5) # Random sample values to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satire: 750\n",
      "Hoax: 750\n",
      "Propaganda: 750\n",
      "Reliable News: 750\n",
      "1    750\n",
      "2    750\n",
      "3    750\n",
      "4    750\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get number of labels for each task\n",
    "classes = ['Satire', 'Hoax', 'Propaganda', 'Reliable News']\n",
    "label_numbers = [1,2,3,4]\n",
    "\n",
    "for label in label_numbers:\n",
    "    print(classes[label-1] + ': ' + str((test_df[0] == label).sum()))\n",
    "print(test_df[0].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Functions\n",
    "- Removal of punctuation in Python Strings, [link](https://datagy.io/python-remove-punctuation-from-string/#:~:text=One%20of%20the%20easiest%20ways,maketrans()%20method.)\n",
    "- Can look at common name removal: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create set of stopwords for use in preprocessing\n",
    "stopword_set = set(stopwords.words('english'))\n",
    "# print(stopword_set)\n",
    "\n",
    "# Fold to lower case\n",
    "def to_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def tokenise_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # print(tokens)\n",
    "    return tokens\n",
    "\n",
    "def remove_stopwords(text, stopword_set):\n",
    "    # Split by whitespace\n",
    "    split_text = text.split()\n",
    "    new_tokens = []\n",
    "    for token in split_text:\n",
    "        if token in stopword_set:\n",
    "            continue\n",
    "        new_tokens.append(token)\n",
    "    # Parse back into text\n",
    "    return ' '.join(new_tokens)\n",
    "\n",
    "# Remove all punctuations - Affects words such as U.S.A etc\n",
    "# Removal of stop words has to be done prior to punctuation removal\n",
    "def remove_punctuation(text):\n",
    "    depunctuated_text = text.translate(str.maketrans('','', string.punctuation))\n",
    "    return depunctuated_text\n",
    "\n",
    "# Prevent concatenation of statistics and names\n",
    "def replace_hyphens(text):\n",
    "    return text.replace('-', ' ')\n",
    "\n",
    "# Combine all processes into a single preprocess text function to call on df\n",
    "def preprocess_text(text):\n",
    "    dehyphenated_text = replace_hyphens(text)\n",
    "    lowered_text = to_lower_case(dehyphenated_text)\n",
    "    initial_stopword_pass = remove_stopwords(lowered_text, stopword_set)\n",
    "    tokens = tokenise_text(initial_stopword_pass)\n",
    "    tokenised_text = ' '.join(tokens)\n",
    "    depunctuated_text = remove_punctuation(tokenised_text)\n",
    "    second_stopword_pass = remove_stopwords(depunctuated_text, stopword_set)\n",
    "    return second_stopword_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing test: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'usa days ago spent 1340 real'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test text preprocessing model\n",
    "test_string = \"I was down in the U.S.A a few days ago! Spent $1,340. But i'll be real, don't do it. Isn't it?\"\n",
    "print('Preprocessing test: ')\n",
    "preprocess_text(test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess all text in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning text...\n",
      "Preprocessing done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>1</td>\n",
       "      <td>marveling aloud many varieties product availab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44362</th>\n",
       "      <td>4</td>\n",
       "      <td>many consumers heard federal government car al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32135</th>\n",
       "      <td>3</td>\n",
       "      <td>spurious terrorism indictments follow natos vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1</td>\n",
       "      <td>securities exchange commission announced tuesd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32444</th>\n",
       "      <td>3</td>\n",
       "      <td>alan grayson tells congress bad suck house cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8444</th>\n",
       "      <td>1</td>\n",
       "      <td>continuing effort destroy roster ultimately ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14977</th>\n",
       "      <td>2</td>\n",
       "      <td>black cop cleared shooting white teen wheres o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38009</th>\n",
       "      <td>3</td>\n",
       "      <td>truth rises coordinated strikes work ways may ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45666</th>\n",
       "      <td>4</td>\n",
       "      <td>cols 5 6 general motor corp long titanic symbo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28922</th>\n",
       "      <td>3</td>\n",
       "      <td>americans treated like terroristsyoutube</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                                  1\n",
       "3742   1  marveling aloud many varieties product availab...\n",
       "44362  4  many consumers heard federal government car al...\n",
       "32135  3  spurious terrorism indictments follow natos vi...\n",
       "170    1  securities exchange commission announced tuesd...\n",
       "32444  3  alan grayson tells congress bad suck house cha...\n",
       "8444   1  continuing effort destroy roster ultimately ca...\n",
       "14977  2  black cop cleared shooting white teen wheres o...\n",
       "38009  3  truth rises coordinated strikes work ways may ...\n",
       "45666  4  cols 5 6 general motor corp long titanic symbo...\n",
       "28922  3           americans treated like terroristsyoutube"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Cleaning text...')\n",
    "df[1] = df[1].map(preprocess_text)\n",
    "print('Preprocessing done!')\n",
    "df.sample(10) # Random sample values to see"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess text in testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning text...\n",
      "Preprocessing done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>3</td>\n",
       "      <td>effort get children drink processed milk conve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>2</td>\n",
       "      <td>watch lois lerners attorney shes innocent one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>2</td>\n",
       "      <td>watch reagans time choosing 50th anniversary f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>1</td>\n",
       "      <td>tempers flared aftermath thursday nights repub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>4</td>\n",
       "      <td>lot talk rules capitol hill lately wednesday r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>2</td>\n",
       "      <td>watch ted cruz identifies four key issues mid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>3</td>\n",
       "      <td>feeding world mantra monsanto multinational co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>4</td>\n",
       "      <td>ballet blood sport hardly begins describe auda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>4</td>\n",
       "      <td>us government seeing hints adversaries targeti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>2</td>\n",
       "      <td>federal court orders one state reinstate dead ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "2048  3  effort get children drink processed milk conve...\n",
       "1176  2  watch lois lerners attorney shes innocent one ...\n",
       "1314  2  watch reagans time choosing 50th anniversary f...\n",
       "545   1  tempers flared aftermath thursday nights repub...\n",
       "2775  4  lot talk rules capitol hill lately wednesday r...\n",
       "1194  2  watch ted cruz identifies four key issues mid ...\n",
       "2046  3  feeding world mantra monsanto multinational co...\n",
       "2701  4  ballet blood sport hardly begins describe auda...\n",
       "2649  4  us government seeing hints adversaries targeti...\n",
       "1089  2  federal court orders one state reinstate dead ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Cleaning text...')\n",
    "test_df[1] = test_df[1].map(preprocess_text)\n",
    "print('Preprocessing done!')\n",
    "test_df.sample(10) # Random sample values to see"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count number of unique words in the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of unique words\n",
    "def unique_word_counter(texts):\n",
    "    count = Counter() # Dictionary type\n",
    "    # Access an entire string\n",
    "    for text in texts:\n",
    "        # Split each string into individual words separated by whitespace\n",
    "        for word in text.split():\n",
    "            count[word] += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 252019\n",
      "Most Common Words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('said', 95152),\n",
       " ('us', 78350),\n",
       " ('one', 64372),\n",
       " ('would', 61931),\n",
       " ('people', 58751),\n",
       " ('government', 45594),\n",
       " ('like', 44459),\n",
       " ('new', 43537),\n",
       " ('time', 43174),\n",
       " ('also', 40434)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run counter\n",
    "counts = unique_word_counter(df[1])\n",
    "unique_words_count = len(counts)\n",
    "print('Number of unique words: ' + str(unique_words_count))\n",
    "print('Most Common Words:')\n",
    "counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare datasets, convert into numpy format for Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(48854,) (3000,)\n",
      "(48854, 4) (3000, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train = df[1].to_numpy()\n",
    "y_train = df[0].to_numpy()\n",
    "\n",
    "X_test = test_df[1].to_numpy()\n",
    "y_test = test_df[0].to_numpy()\n",
    "\n",
    "y_train = pd.get_dummies(df[0]).values\n",
    "y_test = pd.get_dummies(test_df[0]).values\n",
    "print(type(y_train))\n",
    "print(type(y_test))\n",
    "\n",
    "# y_train = y_train - 1\n",
    "# y_test = y_test - 1\n",
    "# temp_y_train = []\n",
    "# for label in y_train:\n",
    "#     temp_y_train.append([label])\n",
    "# y_train = np.array(temp_y_train)\n",
    "# temp_y_test = []\n",
    "# for label in y_test:\n",
    "#     temp_y_test.append([label])\n",
    "# y_test = np.array(temp_y_test)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenise words into numbers\n",
    "- Each word will be assigned a specific number, according to how many unique words we have\n",
    "- Inspired from this [Youtube Video](https://www.youtube.com/watch?v=kxeyoyrf2cM&ab_channel=PythonEngineer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each string is turned into a sequence of integers\n",
    "tokenizer = Tokenizer(num_words=unique_words_count)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad sequences to a common length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts > word length: 2122\n"
     ]
    }
   ],
   "source": [
    "# Determine minimum number of words in a sequence 65218, \n",
    "\n",
    "padding_length = 1000\n",
    "\n",
    "length_count = 0\n",
    "for item in X_train:\n",
    "    length = len(item)\n",
    "    if length > padding_length:\n",
    "        length_count += 1\n",
    "print('Number of texts > word length: ' + str(length_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48854, 1000), (3000, 1000))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=padding_length, padding=\"post\", truncating=\"post\")\n",
    "X_test = pad_sequences(X_test, maxlen=padding_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "# Ensure padded shape of dimension\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the RNN LSTM model\n",
    "- We will be embedding the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9236316220281706515\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1000, 100)         25201900  \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 1000, 100)        0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               80400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,282,704\n",
      "Trainable params: 25,282,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(unique_words_count, output_dim=100, input_length=X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor='val_accuracy', verbose=1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  8/382 [..............................] - ETA: 47:03 - loss: 1.3613 - accuracy: 0.3252"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\School Work\\Y3S2\\CS4248\\Project\\Sample Datasets\\RNN_LSTM.ipynb Cell 31'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/School%20Work/Y3S2/CS4248/Project/Sample%20Datasets/RNN_LSTM.ipynb#ch0000030?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/School%20Work/Y3S2/CS4248/Project/Sample%20Datasets/RNN_LSTM.ipynb#ch0000030?line=2'>3</a>\u001b[0m \u001b[39m# Fit model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/School%20Work/Y3S2/CS4248/Project/Sample%20Datasets/RNN_LSTM.ipynb#ch0000030?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), callbacks\u001b[39m=\u001b[39;49m[model_checkpoint])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/School%20Work/Y3S2/CS4248/Project/Sample%20Datasets/RNN_LSTM.ipynb#ch0000030?line=5'>6</a>\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test, y_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/School%20Work/Y3S2/CS4248/Project/Sample%20Datasets/RNN_LSTM.ipynb#ch0000030?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mLoss: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(loss) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m    \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(accuracy))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/keras/engine/training.py?line=1376'>1377</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/keras/engine/training.py?line=1377'>1378</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/keras/engine/training.py?line=1378'>1379</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/keras/engine/training.py?line=1379'>1380</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/keras/engine/training.py?line=1380'>1381</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/keras/engine/training.py?line=1381'>1382</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/keras/engine/training.py?line=1382'>1383</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/keras/engine/training.py?line=1383'>1384</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/keras/engine/training.py?line=1384'>1385</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/keras/engine/training.py?line=1385'>1386</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Users/dojh1/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128, shuffle=True, validation_data=(X_test, y_test), callbacks=[model_checkpoint])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Loss: ' + str(loss) + '    ' + 'Accuracy: ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Out Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = pd.read_csv(test_path, header=None)\n",
    "sample = new_test.sample(30)\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cleaning text...')\n",
    "sample[1] = sample[1].map(preprocess_text)\n",
    "print('Preprocessing done!')\n",
    "\n",
    "sample_X = sample[1].to_numpy()\n",
    "sample_y = sample[0].to_numpy()\n",
    "sample_y = sample_y - 1\n",
    "\n",
    "classes = ['Satire', 'Hoax', 'Propaganda', 'Reliable News']\n",
    "actual_labels = []\n",
    "for label in sample_y:\n",
    "    actual_labels.append(classes[label])\n",
    "print(actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_X = tokenizer.texts_to_sequences(sample_X)\n",
    "sample_X = pad_sequences(sample_X, maxlen=padding_length, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predictions = []\n",
    "for test_instance in sample_X:\n",
    "    prediction = model.predict(test_instance)\n",
    "    predictions.append(classes[np.argmax(prediction)])\n",
    "\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21df0356f9123b9ffe2140fcee819cd2cf32077b8756437e0847ceff6279ac46"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
