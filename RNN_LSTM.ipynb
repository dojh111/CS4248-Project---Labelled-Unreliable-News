{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN LSTM Text Classificaiton model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string                           # For removal of punctuation\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# os.chdir('drive/MyDrive/School Work/CS4248/News Labelling Project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data into pd dataframes, data viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Total rows, Total Columns: (48854, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47952</th>\n",
       "      <td>4</td>\n",
       "      <td>Matt Szczur said he just did what anyone who w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29152</th>\n",
       "      <td>3</td>\n",
       "      <td>Wests Undermining of UN Paves Way for NATO Syr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10926</th>\n",
       "      <td>1</td>\n",
       "      <td>Saying that he makes a point to simply tune ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48590</th>\n",
       "      <td>4</td>\n",
       "      <td>Former Yuanta Financial Holding President Ma W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35200</th>\n",
       "      <td>3</td>\n",
       "      <td>Chasing Happiness: Ill Be Happy When...SSP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                                  1\n",
       "47952  4  Matt Szczur said he just did what anyone who w...\n",
       "29152  3  Wests Undermining of UN Paves Way for NATO Syr...\n",
       "10926  1  Saying that he makes a point to simply tune ou...\n",
       "48590  4  Former Yuanta Financial Holding President Ma W...\n",
       "35200  3        Chasing Happiness: Ill Be Happy When...SSP "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file in\n",
    "train_path = './raw_data/fulltrain.csv'\n",
    "test_path = './raw_data/balancedtest.csv'\n",
    "df = pd.read_csv(train_path, header=None)\n",
    "\n",
    "print(type(df))\n",
    "\n",
    "# Samples, number of columns, 0 = labels, column 1 = text\n",
    "print('Total rows, Total Columns: ' + str(df.shape))\n",
    "df.sample(5) # Random sample values to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satire: 14047\n",
      "Hoax: 6942\n",
      "Propaganda: 17870\n",
      "Reliable News: 9995\n",
      "3    17870\n",
      "1    14047\n",
      "4     9995\n",
      "2     6942\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get number of labels for each task\n",
    "classes = ['Satire', 'Hoax', 'Propaganda', 'Reliable News']\n",
    "label_numbers = [1,2,3,4]\n",
    "\n",
    "for label in label_numbers:\n",
    "    print(classes[label-1] + ': ' + str((df[0] == label).sum()))\n",
    "print(df[0].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows, Total Columns:       0                                                  1\n",
      "0     1  When so many actors seem content to churn out ...\n",
      "1     1   In what football insiders are calling an unex...\n",
      "2     1  In a freak accident following Game 3 of the N....\n",
      "3     1  North Koreas official news agency announced to...\n",
      "4     1  The former Alaska Governor Sarah Palin would b...\n",
      "...  ..                                                ...\n",
      "2995  4  The Air Force mistakenly gave rival companies ...\n",
      "2996  4  The United Nations climate chief on Friday cha...\n",
      "2997  4  River Plate midfielder Diego Buonanotte has un...\n",
      "2998  4  Lawmakers were on the brink Tuesday of exempti...\n",
      "2999  4  The Pentagon, which is processing bids on a ne...\n",
      "\n",
      "[3000 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>2</td>\n",
       "      <td>Taliban KILL At Least 20 Children And One Sold...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>1</td>\n",
       "      <td>In a dramatic narrative that could upstage thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>1</td>\n",
       "      <td>A new poll released Wednesday revealed that p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>2</td>\n",
       "      <td>Judge Jeanine Compares Reaction Of Candidates ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>2</td>\n",
       "      <td>Wikileaks Assange On Clintons Russia Experts J...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "1041  2  Taliban KILL At Least 20 Children And One Sold...\n",
       "500   1  In a dramatic narrative that could upstage thi...\n",
       "460   1   A new poll released Wednesday revealed that p...\n",
       "1360  2  Judge Jeanine Compares Reaction Of Candidates ...\n",
       "1481  2  Wikileaks Assange On Clintons Russia Experts J..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_path, header=None)\n",
    "\n",
    "# Samples, number of columns, 0 = labels, column 1 = text\n",
    "print('Total rows, Total Columns: ' + str(test_df))\n",
    "test_df.sample(5) # Random sample values to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satire: 750\n",
      "Hoax: 750\n",
      "Propaganda: 750\n",
      "Reliable News: 750\n",
      "1    750\n",
      "2    750\n",
      "3    750\n",
      "4    750\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get number of labels for each task\n",
    "classes = ['Satire', 'Hoax', 'Propaganda', 'Reliable News']\n",
    "label_numbers = [1,2,3,4]\n",
    "\n",
    "for label in label_numbers:\n",
    "    print(classes[label-1] + ': ' + str((test_df[0] == label).sum()))\n",
    "print(test_df[0].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count number of unique words in the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of unique words\n",
    "def unique_word_counter(texts):\n",
    "    count = Counter() # Dictionary type\n",
    "    # Access an entire string\n",
    "    for text in texts:\n",
    "        # Split each string into individual words separated by whitespace\n",
    "        for word in text.split():\n",
    "            count[word] += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run counter\n",
    "counts = unique_word_counter(df[1])\n",
    "unique_words_count = len(counts)\n",
    "print('Number of unique words: ' + str(unique_words_count))\n",
    "print('Most Common Words:')\n",
    "counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare datasets, convert into numpy format for Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[1].to_numpy()\n",
    "y_train = df[0].to_numpy()\n",
    "\n",
    "X_test = test_df[1].to_numpy()\n",
    "y_test = test_df[0].to_numpy()\n",
    "\n",
    "y_train = pd.get_dummies(df[0]).values\n",
    "y_test = pd.get_dummies(test_df[0]).values\n",
    "print(type(y_train))\n",
    "print(type(y_test))\n",
    "\n",
    "# y_train = y_train - 1\n",
    "# y_test = y_test - 1\n",
    "# temp_y_train = []\n",
    "# for label in y_train:\n",
    "#     temp_y_train.append([label])\n",
    "# y_train = np.array(temp_y_train)\n",
    "# temp_y_test = []\n",
    "# for label in y_test:\n",
    "#     temp_y_test.append([label])\n",
    "# y_test = np.array(temp_y_test)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenise words into numbers\n",
    "- Each word will be assigned a specific number, according to how many unique words we have\n",
    "- Inspired from this [Youtube Video](https://www.youtube.com/watch?v=kxeyoyrf2cM&ab_channel=PythonEngineer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each string is turned into a sequence of integers\n",
    "tokenizer = Tokenizer(num_words=unique_words_count)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad sequences to a common length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine minimum number of words in a sequence 65218, \n",
    "\n",
    "padding_length = 1000\n",
    "\n",
    "length_count = 0\n",
    "for item in X_train:\n",
    "    length = len(item)\n",
    "    if length > padding_length:\n",
    "        length_count += 1\n",
    "print('Number of texts > word length: ' + str(length_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=padding_length, padding=\"post\", truncating=\"post\")\n",
    "X_test = pad_sequences(X_test, maxlen=padding_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "# Ensure padded shape of dimension\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the RNN LSTM model\n",
    "- We will be embedding the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(unique_words_count, output_dim=100, input_length=X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"RNN_LSTM.h5\", save_best_only=True, monitor='val_accuracy', verbose=1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128, shuffle=True, validation_data=(X_test, y_test), callbacks=[model_checkpoint])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Loss: ' + str(loss) + '    ' + 'Accuracy: ' + str(accuracy))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21df0356f9123b9ffe2140fcee819cd2cf32077b8756437e0847ceff6279ac46"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
